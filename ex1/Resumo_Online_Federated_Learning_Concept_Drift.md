---
T√≠tulo: Online Federated Learning via Non-Stationary Detection and Adaptation Amidst Concept Drift
Autor(es): Bhargav Ganguly, Vaneet Aggarwal
Data: February 2024
Fonte: IEEE/ACM Transactions on Networking, Vol. 32, No. 1
Palavras-chave: Federated Learning, Non-Stationary, Concept Drift, Dynamic Regret, Online Convex Optimization
---
**Resumo/Abstract**

Este trabalho prop√µe um framework algor√≠tmico multi-escala que combina garantias te√≥ricas dos algoritmos FedAvg e FedOMD em configura√ß√µes quase estacion√°rias com t√©cnicas de detec√ß√£o e adapta√ß√£o n√£o-estacion√°rias para melhorar o desempenho de generaliza√ß√£o do FL na presen√ßa de concept drifts.

# üìå Problema e Contexto
**Qual √© o problema abordado? Por que ele √© importante?**  
- A literatura existente em Federated Learning (FL) assume processos de gera√ß√£o de dados estacion√°rios, o que √© irrealista em condi√ß√µes do mundo real onde ocorrem concept drifts
- Concept drifts ocorrem devido a observa√ß√µes sazonais, falhas em sensores, mudan√ßas abruptas no ambiente (ex: pandemia afetando dados de reservas de voos)
- Metodologias convencionais como FedAvg s√£o agn√≥sticas a essas mudan√ßas temporais nos dados, resultando em piores resultados de generaliza√ß√£o
- √â cr√≠tico aumentar esses frameworks de aprendizado com procedimentos de detec√ß√£o e adapta√ß√£o de n√£o-estacionaridade

# üéØ Objetivo do Estudo
**O que o estudo pretende resolver ou demonstrar?**  
- Desenvolver um framework multi-escala que pode equipar qualquer metodologia FL baseline que funcione bem em ambientes quase estacion√°rios
- Proporcionar a primeira an√°lise de regret din√¢mico para otimiza√ß√£o convexa online para fun√ß√µes convexas gerais no contexto de FL
- Demonstrar bounds de regret din√¢mico em termos do n√∫mero de mudan√ßas de drift (L) e magnitude cumulativa de drift (‚àÜ)
- Criar testes de detec√ß√£o de drift n√£o baseados apenas em heur√≠sticas, mas fundamentados matematicamente

# üõ†Ô∏è Metodologia
**Como o estudo foi conduzido?**  
- Tipo de pesquisa: Te√≥rico-experimental com an√°lise matem√°tica rigorosa e valida√ß√£o experimental
- Ferramentas e t√©cnicas utilizadas: 
  - Framework algor√≠tmico multi-escala (Master-FL)
  - Procedimento de agendamento randomizado para inst√¢ncias de algoritmos base
  - Dois testes de detec√ß√£o de drift (Test 1 e Test 2) baseados em decomposi√ß√£o matem√°tica do regret din√¢mico
- Algoritmos/m√©todos: 
  - Algoritmos base: FedAvg e FedOMD
  - Multi-Scale FL Runner (MSFR)
  - Testes de n√£o-estacionaridade com fundamenta√ß√£o te√≥rica
- Dataset e experimenta√ß√£o: 
  - Datasets LIBSVM: covtype e mnist
  - 20 clientes DPUs, 500 rounds de treinamento
  - Dois tipos de concept drift: Class Introduction (CI) e Class Swap (CS)
  - Compara√ß√£o com FedNova e FedProx

# üìä Resultados Obtidos
**Quais foram as descobertas principais?**  
- Bound de regret din√¢mico de √ï(min{‚àöLT, ‚àÜ^(1/3)T^(2/3) + ‚àöT}) para T rounds
- Framework preserva propriedades dos algoritmos base FL em horizontes quase estacion√°rios
- Complexidade de armazenamento limitada por √ï(C(T)) inst√¢ncias sobre horizonte T
- Experimentalmente, Master-FL-FedAvg e Master-FL-FedOMD superam m√©todos competidores
- Capacidade de re-treinamento r√°pido de modelos impactados por concept drift
- Primeira an√°lise rigorosa de regret din√¢mico para FL n√£o-estacion√°rio

# üîç An√°lise e Discuss√£o
**Quais s√£o as implica√ß√µes dos resultados? Como eles se relacionam com o problema inicial?**  
- O framework resolve o problema fundamental de FL assumir dados estacion√°rios
- Os testes de detec√ß√£o s√£o matematicamente fundamentados (n√£o apenas heur√≠sticos) atrav√©s da decomposi√ß√£o do regret din√¢mico
- O bound obtido √© mais apertado que trabalhos anteriores em otimiza√ß√£o distribu√≠da
- A abordagem multi-escala permite detec√ß√£o eficiente de drifts "s√∫bitos" (Test 1) e "graduais" (Test 2)
- Framework √© geral e pode ser aplicado a outros algoritmos FL que funcionem bem em configura√ß√µes quase estacion√°rias
- Resultados experimentais confirmam a efic√°cia te√≥rica do m√©todo

# ‚úÖ Conclus√£o e Impacto
**Qual √© a principal contribui√ß√£o do artigo? H√° recomenda√ß√µes futuras?**  
- Primeira an√°lise de regret din√¢mico para otimiza√ß√£o federated n√£o-estacion√°ria com fun√ß√µes convexas gerais
- Framework unificado que combina algoritmos FL baseline com detec√ß√£o/adapta√ß√£o de mudan√ßas
- Bounds te√≥ricos rigorosos sem necessidade de conhecimento pr√©vio de L, ‚àÜ ou T
- **Trabalhos futuros recomendados:**
  - Estender para outros algoritmos FL baseline al√©m de FedAvg e FedOMD
  - Considerar abordagens de sele√ß√£o de clientes para dados n√£o-estacion√°rios heterog√™neos
  - Investiga√ß√£o detalhada de t√©cnicas de preserva√ß√£o de privacidade para computa√ß√£o de loss

# üìö Refer√™ncias Adicionais
- Sugiyama & Kawanabe (2012) - Machine Learning in Non-Stationary Environments
- McMahan et al. (2017) - Communication-Efficient Learning (FedAvg original)
- Wei & Luo (2021) - Non-stationary reinforcement learning (base para framework multi-escala)
- Mallick et al. (2022) - Matchmaker: Data drift mitigation in ML
- Wang et al. (2020) - FedNova: Tackling objective inconsistency in heterogeneous FL